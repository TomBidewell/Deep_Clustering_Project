Cluster analysis is a cornerstone of machine learning, involving the grouping of unlabelled data and spanning a diverse range of applications from image detection to customer segmentation. This demand for high-quality clusters has led to the integration of deep learning techniques, such as AutoEncoders and Kullback-Leibler (KL) loss, into the clustering algorithm, exemplified by Deep Embedded Clustering (DEC) in 2016 \cite{DEC}. However, existing literature tends to favour softer probabilistic targets in the KL loss over simpler alternatives. Our study challenges this trend by proposing \textit{deltaDEC}, which employs the nearest cluster Delta Distribution as the target distribution. We demonstrate that this approach can yield significantly superior clustering results compared to conventional distributions. Our research underscores the importance of revisiting simpler methodologies and their potential to enhance clustering performance across a wide variety of domains.
